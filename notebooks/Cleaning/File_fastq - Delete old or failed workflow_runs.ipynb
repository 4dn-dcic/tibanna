{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from core.utils import Tibanna\n",
    "from core import ff_utils\n",
    "from datetime import datetime\n",
    "\n",
    "# set enviroment and key/connection\n",
    "env = 'fourfront-webdev'\n",
    "tibanna = Tibanna(env=env)\n",
    "ff = ff_utils.fdn_connection(key=tibanna.ff_keys)\n",
    "\n",
    "def get_wfr_report(wfr):\n",
    "    \"\"\"For a given workflow_run_sbg item, grabs details, uuid, run_status, wfr name, date, and run time\"\"\"\n",
    "    wfr_data= ff_utils.get_metadata(wfr , connection=ff)\n",
    "    wfr_uuid = wfr_data['uuid']\n",
    "    wfr_status = wfr_data['run_status']\n",
    "    wfr_name = wfr_data['title'].split(' run ')[0]\n",
    "    wfr_time = datetime.strptime(wfr_data['date_created'],'%Y-%m-%dT%H:%M:%S.%f+00:00')\n",
    "    run_hours = (datetime.now()-wfr_time).total_seconds()/3600\n",
    "    wfr_name_list = wfr_data['title'].split(' run ')[0].split('/')\n",
    "    wfr_name = wfr_name_list[0]\n",
    "    try:\n",
    "        wfr_rev = wfr_name_list[1] \n",
    "    except:\n",
    "        wfr_rev = \"0\"\n",
    "    wfr_rep = {'wfr_uuid': wfr_data['uuid'],\n",
    "               'wfr_status': wfr_data['run_status'],\n",
    "               'wfr_name': wfr_name,\n",
    "               'wfr_rev': wfr_rev,\n",
    "               'wfr_date': wfr_time,\n",
    "               'run_time': run_hours}\n",
    "    return wfr_rep\n",
    "\n",
    "    \n",
    "def printTable(myDict, colList=None):\n",
    "    \"\"\" Pretty print a list of dictionaries Author: Thierry Husson\"\"\"\n",
    "    if not colList: colList = list(myDict[0].keys() if myDict else [])\n",
    "    myList = [colList] # 1st row = header\n",
    "    for item in myDict: myList.append([str(item[col] or '') for col in colList])\n",
    "    colSize = [max(map(len,col)) for col in zip(*myList)]\n",
    "    formatStr = ' | '.join([\"{{:<{}}}\".format(i) for i in colSize])\n",
    "    myList.insert(1, ['-' * i for i in colSize]) # Seperating line\n",
    "    for item in myList: print(formatStr.format(*item))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'wfr_status': u'complete', 'wfr_date': datetime.datetime(2017, 7, 18, 15, 15, 4, 313496), 'wfr_name': u'hi-c-processing-partb', 'run_time': 19.657053276944445, 'wfr_rev': u'28', 'wfr_uuid': u'3bb84eba-aded-41b1-8294-6801ff7831ed'}\n",
      "{'wfr_status': u'complete', 'wfr_date': datetime.datetime(2017, 7, 16, 19, 39, 33, 891326), 'wfr_name': u'hi-c-processing-parta-juicer', 'run_time': 63.248908236666665, 'wfr_rev': u'25', 'wfr_uuid': u'a3ad1c5c-a01e-41b0-8089-e0fef9aee0e4'}\n",
      "{'wfr_status': u'complete', 'wfr_date': datetime.datetime(2017, 6, 22, 18, 25, 33, 908169), 'wfr_name': u'md5', 'run_time': 640.4822996874999, 'wfr_rev': '0', 'wfr_uuid': u'da7afb09-53e2-4650-9671-9fa3caf1952c'}\n",
      "{'wfr_status': u'running', 'wfr_date': datetime.datetime(2017, 6, 23, 16, 10, 18, 665551), 'wfr_name': u'fastqc-0-11-4-1', 'run_time': 618.7365975469444, 'wfr_rev': u'1', 'wfr_uuid': u'33041c9e-b500-47ab-bf60-37aeb66c8150'}\n"
     ]
    }
   ],
   "source": [
    "list_wfr = ['3bb84eba-aded-41b1-8294-6801ff7831ed',\n",
    "            'a3ad1c5c-a01e-41b0-8089-e0fef9aee0e4',\n",
    "            'da7afb09-53e2-4650-9671-9fa3caf1952c',\n",
    "            '33041c9e-b500-47ab-bf60-37aeb66c8150']\n",
    "for wfr in list_wfr:\n",
    "    print get_wfr_report(wfr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want to delete old workflowruns (if not, only report will be displayed (y/n))\n",
      "wfr_status                    | wfr_date                   | wfr_name                     | run_time      | wfr_rev | wfr_uuid                            \n",
      "----------------------------- | -------------------------- | ---------------------------- | ------------- | ------- | ------------------------------------\n",
      "complete                      | 2017-05-12 21:58:12.262857 | md5                          | 1601.94532359 | 0       | 102e8aa3-8974-415d-93b5-ebd3439ea7d9\n",
      "complete                      | 2017-05-15 21:43:58.245989 | fastqc-0-11-4-1              | 1530.18259124 | 1       | f7a23d37-c9fb-4a53-8527-9ea6bd8a949a\n",
      "output_file_transfer_finished | 2017-06-01 20:10:14.323227 | hi-c-processing-parta-juicer | 1123.74483484 | 5       | f45d8d45-dc8f-47e6-b9c0-19952f1ea6b4\n",
      "0  old workflowruns from 0 files need to be deleted\n",
      "0 md5 runs and 0 fastqc runs are problematic and need to be deleted\n"
     ]
    }
   ],
   "source": [
    "# This script is looking at the given enviroment and going through all the input files\n",
    "# to see if any of then have a mising/deleted/obsolete input file.\n",
    "# The first part is only reporting, and the second part is if you want to change the status\n",
    "# to deleted and also delete output files.\n",
    "# Give it some time before rerunning\n",
    "\n",
    "delete_workflows = raw_input(\"Do you want to delete old workflowruns (if not, only report will be displayed (y/n))\")\n",
    "\n",
    "# what kind of files should be searched for worflow run inputs, use url compatible naming\n",
    "raw_file_types = ['files-fastq']\n",
    "\n",
    "# accepted workflows\n",
    "workflow_details = [{'wf_name':'md5', 'revision':['0']},\n",
    "                    {'wf_name':'fastqc-0-11-4-1', 'revision':['1']},\n",
    "                    {'wf_name':'hi-c-processing-parta-juicer', 'revision':['25','26']},\n",
    "                    {'wf_name':'hi-c-processing-partb', 'revision':['28']},\n",
    "                    {'wf_name':'hi-c-processing-partc', 'revision':['2']}\n",
    "                   ]\n",
    " \n",
    "deleted_wfr_no = 0\n",
    "files_with_deleted_wfr = 0\n",
    "deleted_last_md5 = 0\n",
    "deleted_last_fastqc = 0\n",
    "\n",
    "# get all wfr\n",
    "for raw_file_type in raw_file_types:\n",
    "    # get all files for the given file type\n",
    "    files = ff_utils.get_metadata(raw_file_type , connection=ff)['@graph']\n",
    "    for raw_file in files:\n",
    "        # switch for counting files with deleted workflow_runs\n",
    "        deleted_wf = False\n",
    "        wfr_report = []\n",
    "        wfrs = raw_file.get('workflow_run_inputs')\n",
    "        # get a report on all workflow_runs\n",
    "        if wfrs:\n",
    "            for wfr in wfrs:\n",
    "                wfr_report.append(get_wfr_report(wfr))  \n",
    "        # sort the report by date and name\n",
    "        wfr_report = sorted(wfr_report, key=lambda k: (k['wfr_date'], k['wfr_name']))\n",
    "        printTable(wfr_report)\n",
    "        break\n",
    "        \n",
    "        \n",
    "        #printTable(wfr_report,['wfr_date', 'wfr_name']) \n",
    "        for wf_name in workflow_names:\n",
    "            #for each type of worklow make a list of old ones, and patch status and description\n",
    "            sub_list_del = [i for i in wfr_report if i['wfr_name'] == wf_name][:-1]\n",
    "            if sub_list_del:\n",
    "                deleted_wf = True\n",
    "                for wfr_to_del in sub_list_del:\n",
    "                    deleted_wfr_no += 1\n",
    "                    if delete_workflows.lower() in ['y', 'yes']:\n",
    "                        patch_data = {'description': \"This workflow run is deleted since there was a new run\",\n",
    "                                      'status': \"deleted\"}\n",
    "                        ff_utils.patch_metadata(patch_data, obj_id=wfr_to_del['wfr_uuid'] ,connection=ff)\n",
    "        \n",
    "            #for each type of workflow check if the active one functional, if not, delete\n",
    "            try:\n",
    "                active_wfr = [i for i in wfr_report if i['wfr_name'] == wf_name][-1]\n",
    "            except:\n",
    "                continue\n",
    "            if active_wfr['wfr_status'] != 'complete':\n",
    "                if wf_name == 'md5':\n",
    "                    # if it is more than 1 hour, it is not really running\n",
    "                    if active_wfr['run_time']>1:\n",
    "                        deleted_last_md5 += 1\n",
    "                        if delete_workflows.lower() in ['y', 'yes']:\n",
    "                            patch_data = {'status': \"deleted\"}\n",
    "                            ff_utils.patch_metadata(patch_data, obj_id=active_wfr['wfr_uuid'] ,connection=ff)\n",
    "                        \n",
    "                if wf_name == 'fastqc-0-11-4-1/1':\n",
    "                    # if it is more than 24 hours, it is not really running\n",
    "                    if active_wfr['run_time']>24:\n",
    "                        deleted_last_fastqc += 1 \n",
    "                        if delete_workflows.lower() in ['y', 'yes']:\n",
    "                            patch_data = {'status': \"deleted\"}\n",
    "                            ff_utils.patch_metadata(patch_data, obj_id=active_wfr['wfr_uuid'] ,connection=ff)\n",
    "              \n",
    "            \n",
    "        if deleted_wf:\n",
    "            files_with_deleted_wfr += 1\n",
    "        break\n",
    "\n",
    "if delete_workflows.lower() in ['y', 'yes']:\n",
    "    print str(deleted_wfr_no),\" old workflowruns from\", str(files_with_deleted_wfr), \"files deleted\"\n",
    "    print str(deleted_last_md5), \"md5 runs and\", str(deleted_last_fastqc), \"fastqc runs are problematic and deleted\"\n",
    "else:\n",
    "    print str(deleted_wfr_no),\" old workflowruns from\", str(files_with_deleted_wfr), \"files need to be deleted\"\n",
    "    print str(deleted_last_md5), \"md5 runs and\", str(deleted_last_fastqc), \"fastqc runs are problematic and need to be deleted\"        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you wanna run md5 and/or fastqc if missing? (md5/qc/all/none)md5\n",
      "1\n",
      "md5 running for 4DNFIULVNKJV\n",
      "about to start run md5_4DNFIULVNKJV.fastq.gz\n",
      "response from aws was: \n",
      " {u'startDate': datetime.datetime(2018, 4, 2, 14, 53, 41, 396000, tzinfo=tzlocal()), 'ResponseMetadata': {'RetryAttempts': 0, 'HTTPStatusCode': 200, 'RequestId': '29344646-36a7-11e8-9ec6-151cafee7e2b', 'HTTPHeaders': {'x-amzn-requestid': '29344646-36a7-11e8-9ec6-151cafee7e2b', 'content-length': '134', 'content-type': 'application/x-amz-json-1.0'}}, u'executionArn': u'arn:aws:states:us-east-1:643366669028:execution:tibanna_pony:md5_4DNFIULVNKJV.fastq.gz'}\n",
      "url to view status:\n",
      "https://console.aws.amazon.com/states/home?region=us-east-1#/executions/details/arn:aws:states:us-east-1:643366669028:execution:tibanna_pony:md5_4DNFIULVNKJV.fastq.gz\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tasks import run_md5\n",
    "from tasks import run_fastqc\n",
    "from invoke import run\n",
    "import time\n",
    "from datetime import datetime\n",
    "from core.utils import Tibanna\n",
    "from core import ff_utils\n",
    "\n",
    "wf_md5 = \"md5\"\n",
    "wf_fastqc = \"fastqc-0-11-4-1\"\n",
    "\n",
    "env = 'fourfront-webprod'\n",
    "tibanna = Tibanna(env=env)\n",
    "run_md_qc = raw_input(\"Do you wanna run md5 and/or fastqc if missing? (md5/qc/all/none)\")\n",
    "\n",
    "# status for completion\n",
    "# there are two flavors of complete signals, before it was output_file_transfer_finished, not it is complete.\n",
    "# old completed wf runs have former one.\n",
    "\n",
    "ff = ff_utils.fdn_connection(key=tibanna.ff_keys)\n",
    "\n",
    "################\n",
    "##ADD TO WORKFLOW\n",
    "# wfr_time = datetime.strptime(wfr_data['date_created'],'%Y-%m-%dT%H:%M:%S.%f+00:00')\n",
    "# run_hours = int((datetime.now()-wfr_time).total_seconds()/3600)\n",
    "################\n",
    "\n",
    "def get_files(exp_set_id):\n",
    "    files = []\n",
    "    exps = ff_utils.get_metadata(exp_set_id, connection=ff)['experiments_in_set']\n",
    "    for an_exp in exps:\n",
    "        exp_resp = ff_utils.get_metadata(an_exp, connection=ff)['files']\n",
    "        files.extend(exp_resp)\n",
    "    return files\n",
    "\n",
    "def summarize_file(file_resp):\n",
    "    md5 = False\n",
    "    qc = False\n",
    "    file_id = file_resp['accession']\n",
    "    sequencer = file_resp.get('instrument')\n",
    "    relations = file_resp.get('related_files')\n",
    "    status = file_resp.get('status')\n",
    "    workflows = file_resp.get('workflow_run_inputs')\n",
    "    #first_alias = file_resp.get('aliases',[None])[0]\n",
    "    pair_no = file_resp.get('paired_end')\n",
    "    # is md5 fine\n",
    "    if file_resp.get('content_md5sum'):\n",
    "        md5 = True\n",
    "    # is there md5sum for gzip\n",
    "    if not file_resp.get('md5sum'):\n",
    "        print file_id,\"does not have the md5sum calculated during upload\"\n",
    "        \n",
    "    # is there a qc?\n",
    "    if file_resp.get('quality_metric'):\n",
    "        qc = True\n",
    "    # Check workflows for qc fastqc workflow partA\n",
    "    md5_status = 'did_not_run'\n",
    "    fastqc_status = 'did_not_run'\n",
    "    # Assumes workflow_runs come in time ordered list, and grabs the last ones for each wf run\n",
    "    if workflows:\n",
    "        for a_wfr in workflows:\n",
    "            wfr_resp = ff_utils.get_metadata(a_wfr['uuid'], connection=ff)\n",
    "            wfr_name = wfr_resp['display_title']\n",
    "            if wfr_name.startswith(wf_md5):\n",
    "                md5_status = wfr_resp.get('run_status')     \n",
    "            elif wfr_name.startswith(wf_fastqc):\n",
    "                fastqc_status = wfr_resp.get('run_status') \n",
    "            \n",
    "                \n",
    "    # Check for md5 and fastqc, and if not complete, run or report it. \n",
    "    # if exclude miseq is on, do this only if sequencer is not miseq\n",
    "\n",
    "    if not md5 or status in [\"uploading\", \"upload failed\"] or md5_status != 'complete':\n",
    "        # if not, shall we run it?\n",
    "        if run_md_qc in ['md5', 'all']:\n",
    "            print 'md5 running for', file_resp['accession']\n",
    "            code_md5= \"invoke run_md5 \" + env + \" \" + file_resp['accession'] + \" \" + file_resp['uuid']\n",
    "            run(code_md5)\n",
    "            print ''\n",
    "            time.sleep(3)\n",
    "        # user does not want it to be run, so just report\n",
    "        else:\n",
    "            print 'md5 run missing for', file_resp['accession']\n",
    "    # check fastqc if md5 is fine\n",
    "    else:\n",
    "        if not qc or fastqc_status != 'complete':\n",
    "            # if not, shall we run it?\n",
    "            if run_md_qc in ['qc', 'all']:\n",
    "                print 'fastqc running for', file_resp['accession']\n",
    "                code_qc= \"invoke run_fastqc \" + env + \" \" + file_resp['accession'] + \" \" + file_resp['uuid']\n",
    "                run(code_qc)\n",
    "                print ''    \n",
    "                time.sleep(3)\n",
    "            # user does not want it to be run, so just report\n",
    "            else:\n",
    "                print 'fastqc run missing for', file_resp['accession'], fastqc_status\n",
    "                print \n",
    "    return\n",
    "\n",
    "\n",
    "# file_url = '/search/?type=FileFastq&limit=all&q=date_created%3A%3E%3D2016-09-01'\n",
    "# all_files = ff_utils.get_metadata('files-fastq', connection=ff)['@graph']\n",
    "\n",
    "all_files = [ff_utils.get_metadata('4DNFIULVNKJV', connection=ff)]\n",
    "\n",
    "\n",
    "print len(all_files)\n",
    "\n",
    "\n",
    "printn = 0\n",
    "counter = 0\n",
    "for a_file in all_files:  \n",
    "    counter += 1\n",
    "    # check for deleted or weird cases\n",
    "    try:\n",
    "        if a_file['status'] == 'deleted':\n",
    "            #print \"Deleted File\", a_file\n",
    "            continue\n",
    "    except:\n",
    "        print a_file\n",
    "        break\n",
    "        \n",
    "    if counter-printn > 100:\n",
    "        print counter\n",
    "        printn = counter\n",
    "\n",
    "    file_resp = ff_utils.get_metadata(a_file['uuid'], connection=ff, frame='embedded')\n",
    "    # check if file is in s3\n",
    "    head_info = tibanna.s3.does_key_exist(file_resp['upload_key'], tibanna.s3.raw_file_bucket)\n",
    "    if not head_info:\n",
    "        print file_resp['accession'], \"does not have a file in S3\"\n",
    "        continue\n",
    "    file_info = summarize_file(file_resp)\n",
    "    \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

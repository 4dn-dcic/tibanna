{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you wanna run md5 and/or fastqc if missing? (md5/qc/all/none)md5\n",
      "8\n",
      "md5 running for 4DNFIBNAPW30\n",
      "about to start run md5_4DNFIBNAPW30.fastq.gz028bb9b9-0139-4681-b1d9-904b14e6b72a\n",
      "response from aws was: \n",
      " {u'startDate': datetime.datetime(2018, 4, 3, 10, 36, 47, 874000, tzinfo=tzlocal()), 'ResponseMetadata': {'RetryAttempts': 0, 'HTTPStatusCode': 200, 'RequestId': '7074b978-374c-11e8-9be5-916825b66536', 'HTTPHeaders': {'x-amzn-requestid': '7074b978-374c-11e8-9be5-916825b66536', 'content-length': '170', 'content-type': 'application/x-amz-json-1.0'}}, u'executionArn': u'arn:aws:states:us-east-1:643366669028:execution:tibanna_pony:md5_4DNFIBNAPW30.fastq.gz028bb9b9-0139-4681-b1d9-904b14e6b72a'}\n",
      "url to view status:\n",
      "https://console.aws.amazon.com/states/home?region=us-east-1#/executions/details/arn:aws:states:us-east-1:643366669028:execution:tibanna_pony:md5_4DNFIBNAPW30.fastq.gz028bb9b9-0139-4681-b1d9-904b14e6b72a\n",
      "\n",
      "4DNFI823MBKE does not have the md5sum calculated during upload\n",
      "md5 running for 4DNFI823MBKE\n",
      "about to start run md5_4DNFI823MBKE.fastq.gz69888d56-cbc9-45cc-a90b-07c0515d9215\n",
      "response from aws was: \n",
      " {u'startDate': datetime.datetime(2018, 4, 3, 10, 36, 53, 123000, tzinfo=tzlocal()), 'ResponseMetadata': {'RetryAttempts': 0, 'HTTPStatusCode': 200, 'RequestId': '7396b97c-374c-11e8-a6af-a7ff6c296773', 'HTTPHeaders': {'x-amzn-requestid': '7396b97c-374c-11e8-a6af-a7ff6c296773', 'content-length': '170', 'content-type': 'application/x-amz-json-1.0'}}, u'executionArn': u'arn:aws:states:us-east-1:643366669028:execution:tibanna_pony:md5_4DNFI823MBKE.fastq.gz69888d56-cbc9-45cc-a90b-07c0515d9215'}\n",
      "url to view status:\n",
      "https://console.aws.amazon.com/states/home?region=us-east-1#/executions/details/arn:aws:states:us-east-1:643366669028:execution:tibanna_pony:md5_4DNFI823MBKE.fastq.gz69888d56-cbc9-45cc-a90b-07c0515d9215\n",
      "\n",
      "4DNFI823LSII does not have the md5sum calculated during upload\n",
      "md5 running for 4DNFI823LSII\n",
      "about to start run md5_4DNFI823LSII.fastq.gza005f631-7115-4fc2-b37a-6fff237eaaab\n",
      "response from aws was: \n",
      " {u'startDate': datetime.datetime(2018, 4, 3, 10, 36, 58, 764000, tzinfo=tzlocal()), 'ResponseMetadata': {'RetryAttempts': 0, 'HTTPStatusCode': 200, 'RequestId': '76f0ba08-374c-11e8-8b1e-1b3d2075c93b', 'HTTPHeaders': {'x-amzn-requestid': '76f0ba08-374c-11e8-8b1e-1b3d2075c93b', 'content-length': '170', 'content-type': 'application/x-amz-json-1.0'}}, u'executionArn': u'arn:aws:states:us-east-1:643366669028:execution:tibanna_pony:md5_4DNFI823LSII.fastq.gza005f631-7115-4fc2-b37a-6fff237eaaab'}\n",
      "url to view status:\n",
      "https://console.aws.amazon.com/states/home?region=us-east-1#/executions/details/arn:aws:states:us-east-1:643366669028:execution:tibanna_pony:md5_4DNFI823LSII.fastq.gza005f631-7115-4fc2-b37a-6fff237eaaab\n",
      "\n",
      "4DNFI823L812 does not have the md5sum calculated during upload\n",
      "md5 running for 4DNFI823L812\n",
      "about to start run md5_4DNFI823L812.fastq.gz6f989af8-d680-4f59-8af3-5a1ed5e82215\n",
      "response from aws was: \n",
      " {u'startDate': datetime.datetime(2018, 4, 3, 10, 37, 4, 226000, tzinfo=tzlocal()), 'ResponseMetadata': {'RetryAttempts': 0, 'HTTPStatusCode': 200, 'RequestId': '7a34c184-374c-11e8-9be5-916825b66536', 'HTTPHeaders': {'x-amzn-requestid': '7a34c184-374c-11e8-9be5-916825b66536', 'content-length': '170', 'content-type': 'application/x-amz-json-1.0'}}, u'executionArn': u'arn:aws:states:us-east-1:643366669028:execution:tibanna_pony:md5_4DNFI823L812.fastq.gz6f989af8-d680-4f59-8af3-5a1ed5e82215'}\n",
      "url to view status:\n",
      "https://console.aws.amazon.com/states/home?region=us-east-1#/executions/details/arn:aws:states:us-east-1:643366669028:execution:tibanna_pony:md5_4DNFI823L812.fastq.gz6f989af8-d680-4f59-8af3-5a1ed5e82215\n",
      "\n",
      "4DNFI823L811 does not have the md5sum calculated during upload\n",
      "md5 running for 4DNFI823L811\n",
      "about to start run md5_4DNFI823L811.fastq.gz0d8607b7-3ea7-48df-9453-5817ecb2ac18\n",
      "response from aws was: \n",
      " {u'startDate': datetime.datetime(2018, 4, 3, 10, 37, 9, 986000, tzinfo=tzlocal()), 'ResponseMetadata': {'RetryAttempts': 0, 'HTTPStatusCode': 200, 'RequestId': '7da4bb71-374c-11e8-a6af-a7ff6c296773', 'HTTPHeaders': {'x-amzn-requestid': '7da4bb71-374c-11e8-a6af-a7ff6c296773', 'content-length': '170', 'content-type': 'application/x-amz-json-1.0'}}, u'executionArn': u'arn:aws:states:us-east-1:643366669028:execution:tibanna_pony:md5_4DNFI823L811.fastq.gz0d8607b7-3ea7-48df-9453-5817ecb2ac18'}\n",
      "url to view status:\n",
      "https://console.aws.amazon.com/states/home?region=us-east-1#/executions/details/arn:aws:states:us-east-1:643366669028:execution:tibanna_pony:md5_4DNFI823L811.fastq.gz0d8607b7-3ea7-48df-9453-5817ecb2ac18\n",
      "\n",
      "4DNFI823L888 does not have the md5sum calculated during upload\n",
      "md5 running for 4DNFI823L888\n",
      "about to start run md5_4DNFI823L888.fastq.gz98fb6982-dc38-469d-bb6e-9a78cbf430d2\n",
      "response from aws was: \n",
      " {u'startDate': datetime.datetime(2018, 4, 3, 10, 37, 16, 538000, tzinfo=tzlocal()), 'ResponseMetadata': {'RetryAttempts': 0, 'HTTPStatusCode': 200, 'RequestId': '8189218f-374c-11e8-b656-3fac328c82d0', 'HTTPHeaders': {'x-amzn-requestid': '8189218f-374c-11e8-b656-3fac328c82d0', 'content-length': '170', 'content-type': 'application/x-amz-json-1.0'}}, u'executionArn': u'arn:aws:states:us-east-1:643366669028:execution:tibanna_pony:md5_4DNFI823L888.fastq.gz98fb6982-dc38-469d-bb6e-9a78cbf430d2'}\n",
      "url to view status:\n",
      "https://console.aws.amazon.com/states/home?region=us-east-1#/executions/details/arn:aws:states:us-east-1:643366669028:execution:tibanna_pony:md5_4DNFI823L888.fastq.gz98fb6982-dc38-469d-bb6e-9a78cbf430d2\n",
      "\n",
      "md5 running for 4DNFI823LSI8\n",
      "about to start run md5_4DNFI823LSI8.fastq.gz341d7e9c-ce6a-4cdb-bbc0-c7e483399d50\n",
      "response from aws was: \n",
      " {u'startDate': datetime.datetime(2018, 4, 3, 10, 37, 22, 588000, tzinfo=tzlocal()), 'ResponseMetadata': {'RetryAttempts': 0, 'HTTPStatusCode': 200, 'RequestId': '8525f6ac-374c-11e8-bc2b-b109b7abcc88', 'HTTPHeaders': {'x-amzn-requestid': '8525f6ac-374c-11e8-bc2b-b109b7abcc88', 'content-length': '170', 'content-type': 'application/x-amz-json-1.0'}}, u'executionArn': u'arn:aws:states:us-east-1:643366669028:execution:tibanna_pony:md5_4DNFI823LSI8.fastq.gz341d7e9c-ce6a-4cdb-bbc0-c7e483399d50'}\n",
      "url to view status:\n",
      "https://console.aws.amazon.com/states/home?region=us-east-1#/executions/details/arn:aws:states:us-east-1:643366669028:execution:tibanna_pony:md5_4DNFI823LSI8.fastq.gz341d7e9c-ce6a-4cdb-bbc0-c7e483399d50\n",
      "\n",
      "4DNFIZQZ39L9 does not have the md5sum calculated during upload\n",
      "md5 running for 4DNFIZQZ39L9\n",
      "about to start run md5_4DNFIZQZ39L9.fastq.gz907f88e0-9adf-4d27-aed0-562401e6ed78\n",
      "response from aws was: \n",
      " {u'startDate': datetime.datetime(2018, 4, 3, 10, 37, 29, 205000, tzinfo=tzlocal()), 'ResponseMetadata': {'RetryAttempts': 0, 'HTTPStatusCode': 200, 'RequestId': '8915f581-374c-11e8-945c-9b970581f518', 'HTTPHeaders': {'x-amzn-requestid': '8915f581-374c-11e8-945c-9b970581f518', 'content-length': '170', 'content-type': 'application/x-amz-json-1.0'}}, u'executionArn': u'arn:aws:states:us-east-1:643366669028:execution:tibanna_pony:md5_4DNFIZQZ39L9.fastq.gz907f88e0-9adf-4d27-aed0-562401e6ed78'}\n",
      "url to view status:\n",
      "https://console.aws.amazon.com/states/home?region=us-east-1#/executions/details/arn:aws:states:us-east-1:643366669028:execution:tibanna_pony:md5_4DNFIZQZ39L9.fastq.gz907f88e0-9adf-4d27-aed0-562401e6ed78\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tasks import run_md5\n",
    "from tasks import run_fastqc\n",
    "from invoke import run\n",
    "import time\n",
    "from datetime import datetime\n",
    "from core.utils import Tibanna\n",
    "from core import ff_utils\n",
    "\n",
    "wf_md5 = \"md5\"\n",
    "wf_fastqc = \"fastqc-0-11-4-1\"\n",
    "\n",
    "env = 'fourfront-webprod'\n",
    "tibanna = Tibanna(env=env)\n",
    "run_md_qc = raw_input(\"Do you wanna run md5 and/or fastqc if missing? (md5/qc/all/none)\")\n",
    "\n",
    "# status for completion\n",
    "# there are two flavors of complete signals, before it was output_file_transfer_finished, not it is complete.\n",
    "# old completed wf runs have former one.\n",
    "\n",
    "ff = ff_utils.fdn_connection(key=tibanna.ff_keys)\n",
    "\n",
    "################\n",
    "##ADD TO WORKFLOW\n",
    "# wfr_time = datetime.strptime(wfr_data['date_created'],'%Y-%m-%dT%H:%M:%S.%f+00:00')\n",
    "# run_hours = int((datetime.now()-wfr_time).total_seconds()/3600)\n",
    "################\n",
    "\n",
    "def get_files(exp_set_id):\n",
    "    files = []\n",
    "    exps = ff_utils.get_metadata(exp_set_id, connection=ff)['experiments_in_set']\n",
    "    for an_exp in exps:\n",
    "        exp_resp = ff_utils.get_metadata(an_exp, connection=ff)['files']\n",
    "        files.extend(exp_resp)\n",
    "    return files\n",
    "\n",
    "def summarize_file(file_resp):\n",
    "    md5 = False\n",
    "    qc = False\n",
    "    file_id = file_resp['accession']\n",
    "    sequencer = file_resp.get('instrument')\n",
    "    relations = file_resp.get('related_files')\n",
    "    status = file_resp.get('status')\n",
    "    workflows = file_resp.get('workflow_run_inputs')\n",
    "    first_alias = file_resp.get('aliases',[None])[0]\n",
    "    pair_no = file_resp.get('paired_end')\n",
    "    # is md5 fine\n",
    "    if file_resp.get('content_md5sum'):\n",
    "        md5 = True\n",
    "    # is there md5sum for gzip\n",
    "    if not file_resp.get('md5sum'):\n",
    "        print file_id,\"does not have the md5sum calculated during upload\"\n",
    "        \n",
    "    # is there a qc?\n",
    "    if file_resp.get('quality_metric'):\n",
    "        qc = True\n",
    "    # Check workflows for qc fastqc workflow partA\n",
    "    md5_status = 'did_not_run'\n",
    "    fastqc_status = 'did_not_run'\n",
    "    # Assumes workflow_runs come in time ordered list, and grabs the last ones for each wf run\n",
    "    if workflows:\n",
    "        for a_wfr in workflows:\n",
    "            wfr_resp = ff_utils.get_metadata(a_wfr['uuid'], connection=ff)\n",
    "            wfr_name = wfr_resp['display_title']\n",
    "            if wfr_name.startswith(wf_md5):\n",
    "                md5_status = wfr_resp.get('run_status')     \n",
    "            elif wfr_name.startswith(wf_fastqc):\n",
    "                fastqc_status = wfr_resp.get('run_status') \n",
    "            \n",
    "                \n",
    "    # Check for md5 and fastqc, and if not complete, run or report it. \n",
    "    # if exclude miseq is on, do this only if sequencer is not miseq\n",
    "\n",
    "    if not md5 or status in [\"uploading\", \"upload failed\"] or md5_status != 'complete':\n",
    "        # if not, shall we run it?\n",
    "        if run_md_qc in ['md5', 'all']:\n",
    "            print 'md5 running for', file_resp['accession']\n",
    "            code_md5= \"invoke run_md5 \" + env + \" \" + file_resp['accession'] + \" \" + file_resp['uuid']\n",
    "            run(code_md5)\n",
    "            print ''\n",
    "            time.sleep(3)\n",
    "        # user does not want it to be run, so just report\n",
    "        else:\n",
    "            print 'md5 run missing for', file_resp['accession']\n",
    "    # check fastqc if md5 is fine\n",
    "    else:\n",
    "        if not qc or fastqc_status != 'complete':\n",
    "            # if not, shall we run it?\n",
    "            if run_md_qc in ['qc', 'all']:\n",
    "                print 'fastqc running for', file_resp['accession']\n",
    "                code_qc= \"invoke run_fastqc \" + env + \" \" + file_resp['accession'] + \" \" + file_resp['uuid']\n",
    "                run(code_qc)\n",
    "                print ''    \n",
    "                time.sleep(3)\n",
    "            # user does not want it to be run, so just report\n",
    "            else:\n",
    "                print 'fastqc run missing for', file_resp['accession'], fastqc_status\n",
    "                print \n",
    "    return\n",
    "\n",
    "\n",
    "file_url = '/search/?type=FileFastq&limit=all&q=date_created%3A%3E%3D2016-09-01'\n",
    "file_url = '/search/?type=FileReference'\n",
    "#all_files = ff_utils.get_metadata('files-fastq', connection=ff)['@graph']\n",
    "\n",
    "all_files = ff_utils.get_metadata(file_url, connection=ff)['@graph']\n",
    "\n",
    "print len(all_files)\n",
    "\n",
    "\n",
    "printn = 0\n",
    "counter = 0\n",
    "for a_file in all_files:  \n",
    "    counter += 1\n",
    "    # check for deleted or weird cases\n",
    "    try:\n",
    "        if a_file['status'] == 'deleted':\n",
    "            #print \"Deleted File\", a_file\n",
    "            continue\n",
    "    except:\n",
    "        print a_file\n",
    "        break\n",
    "        \n",
    "    if counter-printn > 100:\n",
    "        print counter\n",
    "        printn = counter\n",
    "\n",
    "    file_resp = ff_utils.get_metadata(a_file['uuid'], connection=ff, frame='embedded')\n",
    "    # check if file is in s3\n",
    "    head_info = tibanna.s3.does_key_exist(file_resp['upload_key'], tibanna.s3.raw_file_bucket)\n",
    "    if not head_info:\n",
    "        print file_resp['accession'], \"does not have a file in S3\"\n",
    "        continue\n",
    "    md5 = False\n",
    "    \n",
    "    file_id = file_resp['accession']\n",
    "    status = file_resp.get('status')\n",
    "    workflows = file_resp.get('workflow_run_inputs')\n",
    "    \n",
    "    if file_resp.get('content_md5sum'):\n",
    "        md5 = True\n",
    "        \n",
    "    # is there md5sum for gzip\n",
    "    if not file_resp.get('md5sum'):\n",
    "        print file_id,\"does not have the md5sum calculated during upload\"\n",
    "        \n",
    "    # Check workflows f\n",
    "    md5_status = 'did_not_run'\n",
    "    \n",
    "    \n",
    "    # Assumes workflow_runs come in time ordered list, and grabs the last ones for each wf run\n",
    "    if workflows:\n",
    "        for a_wfr in workflows:\n",
    "            wfr_resp = ff_utils.get_metadata(a_wfr['uuid'], connection=ff)\n",
    "            wfr_name = wfr_resp['display_title']\n",
    "            if wfr_name.startswith(wf_md5):\n",
    "                md5_status = wfr_resp.get('run_status') \n",
    "                \n",
    "    if not md5 or status in [\"uploading\", \"upload failed\"] or md5_status != 'complete':\n",
    "        # if not, shall we run it?\n",
    "        if run_md_qc in ['md5', 'all']:\n",
    "            print 'md5 running for', file_resp['accession']\n",
    "            code_md5= \"invoke run_md5 \" + env + \" \" + file_resp['accession'] + \" \" + file_resp['uuid']\n",
    "            run(code_md5)\n",
    "            print ''\n",
    "            time.sleep(3)\n",
    "        # user does not want it to be run, so just report\n",
    "        else:\n",
    "            print 'md5 run missing for', file_resp['accession']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

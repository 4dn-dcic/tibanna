{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you wanna run md5 and/or fastqc if missing? (md5/qc/all/none)all\n",
      "2755\n",
      "fastqc running for 4DNFIXKHKJ1E\n",
      "about to start run fastqc-0-11-4-1_4DNFIXKHKJ1E.fastq.gz\n",
      "response from aws was: \n",
      " {u'startDate': datetime.datetime(2018, 3, 25, 8, 10, 54, 490000, tzinfo=tzlocal()), 'ResponseMetadata': {'RetryAttempts': 0, 'HTTPStatusCode': 200, 'RequestId': '914ee528-3025-11e8-bffa-2ff892029bb9', 'HTTPHeaders': {'x-amzn-requestid': '914ee528-3025-11e8-bffa-2ff892029bb9', 'content-length': '145', 'content-type': 'application/x-amz-json-1.0'}}, u'executionArn': u'arn:aws:states:us-east-1:643366669028:execution:tibanna_pony:fastqc-0-11-4-1_4DNFIXKHKJ1E.fastq.gz'}\n",
      "url to view status:\n",
      "https://console.aws.amazon.com/states/home?region=us-east-1#/executions/details/arn:aws:states:us-east-1:643366669028:execution:tibanna_pony:fastqc-0-11-4-1_4DNFIXKHKJ1E.fastq.gz\n",
      "\n",
      "fastqc running for 4DNFI1CIZT87\n",
      "about to start run fastqc-0-11-4-1_4DNFI1CIZT87.fastq.gz\n",
      "response from aws was: \n",
      " {u'startDate': datetime.datetime(2018, 3, 25, 8, 10, 59, 947000, tzinfo=tzlocal()), 'ResponseMetadata': {'RetryAttempts': 0, 'HTTPStatusCode': 200, 'RequestId': '9490f14a-3025-11e8-ac71-dd912c487e9f', 'HTTPHeaders': {'x-amzn-requestid': '9490f14a-3025-11e8-ac71-dd912c487e9f', 'content-length': '146', 'content-type': 'application/x-amz-json-1.0'}}, u'executionArn': u'arn:aws:states:us-east-1:643366669028:execution:tibanna_pony:fastqc-0-11-4-1_4DNFI1CIZT87.fastq.gz'}\n",
      "url to view status:\n",
      "https://console.aws.amazon.com/states/home?region=us-east-1#/executions/details/arn:aws:states:us-east-1:643366669028:execution:tibanna_pony:fastqc-0-11-4-1_4DNFI1CIZT87.fastq.gz\n",
      "\n",
      "fastqc running for 4DNFIY7WIH8Y\n",
      "about to start run fastqc-0-11-4-1_4DNFIY7WIH8Y.fastq.gz\n",
      "response from aws was: \n",
      " {u'startDate': datetime.datetime(2018, 3, 25, 8, 11, 5, 579000, tzinfo=tzlocal()), 'ResponseMetadata': {'RetryAttempts': 0, 'HTTPStatusCode': 200, 'RequestId': '97ec2a20-3025-11e8-b87f-b9db9e512020', 'HTTPHeaders': {'x-amzn-requestid': '97ec2a20-3025-11e8-b87f-b9db9e512020', 'content-length': '146', 'content-type': 'application/x-amz-json-1.0'}}, u'executionArn': u'arn:aws:states:us-east-1:643366669028:execution:tibanna_pony:fastqc-0-11-4-1_4DNFIY7WIH8Y.fastq.gz'}\n",
      "url to view status:\n",
      "https://console.aws.amazon.com/states/home?region=us-east-1#/executions/details/arn:aws:states:us-east-1:643366669028:execution:tibanna_pony:fastqc-0-11-4-1_4DNFIY7WIH8Y.fastq.gz\n",
      "\n",
      "md5 running for 4DNFIXIJYKZ1\n",
      "about to start run md5_4DNFIXIJYKZ1.fastq.gzbdb02d1b-c049-48b3-b6fa-c709a3337224\n",
      "response from aws was: \n",
      " {u'startDate': datetime.datetime(2018, 3, 25, 8, 11, 13, 500000, tzinfo=tzlocal()), 'ResponseMetadata': {'RetryAttempts': 0, 'HTTPStatusCode': 200, 'RequestId': '9ca4331e-3025-11e8-9847-c74d5dd923b7', 'HTTPHeaders': {'x-amzn-requestid': '9ca4331e-3025-11e8-9847-c74d5dd923b7', 'content-length': '168', 'content-type': 'application/x-amz-json-1.0'}}, u'executionArn': u'arn:aws:states:us-east-1:643366669028:execution:tibanna_pony:md5_4DNFIXIJYKZ1.fastq.gzbdb02d1b-c049-48b3-b6fa-c709a3337224'}\n",
      "url to view status:\n",
      "https://console.aws.amazon.com/states/home?region=us-east-1#/executions/details/arn:aws:states:us-east-1:643366669028:execution:tibanna_pony:md5_4DNFIXIJYKZ1.fastq.gzbdb02d1b-c049-48b3-b6fa-c709a3337224\n",
      "\n",
      "fastqc running for 4DNFI9QM9KK5\n",
      "about to start run fastqc-0-11-4-1_4DNFI9QM9KK5.fastq.gz\n",
      "response from aws was: \n",
      " {u'startDate': datetime.datetime(2018, 3, 25, 8, 11, 19, 907000, tzinfo=tzlocal()), 'ResponseMetadata': {'RetryAttempts': 0, 'HTTPStatusCode': 200, 'RequestId': 'a0749cf0-3025-11e8-9efb-81e58f2ed1a1', 'HTTPHeaders': {'x-amzn-requestid': 'a0749cf0-3025-11e8-9efb-81e58f2ed1a1', 'content-length': '146', 'content-type': 'application/x-amz-json-1.0'}}, u'executionArn': u'arn:aws:states:us-east-1:643366669028:execution:tibanna_pony:fastqc-0-11-4-1_4DNFI9QM9KK5.fastq.gz'}\n",
      "url to view status:\n",
      "https://console.aws.amazon.com/states/home?region=us-east-1#/executions/details/arn:aws:states:us-east-1:643366669028:execution:tibanna_pony:fastqc-0-11-4-1_4DNFI9QM9KK5.fastq.gz\n",
      "\n",
      "fastqc running for 4DNFIVKXTJ2O\n",
      "about to start run fastqc-0-11-4-1_4DNFIVKXTJ2O.fastq.gz78744b64-9fda-49c6-bf88-846f431fc389\n",
      "response from aws was: \n",
      " {u'startDate': datetime.datetime(2018, 3, 25, 8, 11, 31, 534000, tzinfo=tzlocal()), 'ResponseMetadata': {'RetryAttempts': 0, 'HTTPStatusCode': 200, 'RequestId': 'a764e31f-3025-11e8-bb38-31606f4f1c5f', 'HTTPHeaders': {'x-amzn-requestid': 'a764e31f-3025-11e8-bb38-31606f4f1c5f', 'content-length': '182', 'content-type': 'application/x-amz-json-1.0'}}, u'executionArn': u'arn:aws:states:us-east-1:643366669028:execution:tibanna_pony:fastqc-0-11-4-1_4DNFIVKXTJ2O.fastq.gz78744b64-9fda-49c6-bf88-846f431fc389'}\n",
      "url to view status:\n",
      "https://console.aws.amazon.com/states/home?region=us-east-1#/executions/details/arn:aws:states:us-east-1:643366669028:execution:tibanna_pony:fastqc-0-11-4-1_4DNFIVKXTJ2O.fastq.gz78744b64-9fda-49c6-bf88-846f431fc389\n",
      "\n",
      "fastqc running for 4DNFIH9ETAMJ\n",
      "about to start run fastqc-0-11-4-1_4DNFIH9ETAMJ.fastq.gz82b31762-756b-4d4a-91ca-637182d9f5e3\n",
      "response from aws was: \n",
      " {u'startDate': datetime.datetime(2018, 3, 25, 8, 11, 37, 995000, tzinfo=tzlocal()), 'ResponseMetadata': {'RetryAttempts': 0, 'HTTPStatusCode': 200, 'RequestId': 'ab3d3b76-3025-11e8-86dd-e7203302ff1b', 'HTTPHeaders': {'x-amzn-requestid': 'ab3d3b76-3025-11e8-86dd-e7203302ff1b', 'content-length': '182', 'content-type': 'application/x-amz-json-1.0'}}, u'executionArn': u'arn:aws:states:us-east-1:643366669028:execution:tibanna_pony:fastqc-0-11-4-1_4DNFIH9ETAMJ.fastq.gz82b31762-756b-4d4a-91ca-637182d9f5e3'}\n",
      "url to view status:\n",
      "https://console.aws.amazon.com/states/home?region=us-east-1#/executions/details/arn:aws:states:us-east-1:643366669028:execution:tibanna_pony:fastqc-0-11-4-1_4DNFIH9ETAMJ.fastq.gz82b31762-756b-4d4a-91ca-637182d9f5e3\n",
      "\n",
      "fastqc running for 4DNFIGJE83W2\n",
      "about to start run fastqc-0-11-4-1_4DNFIGJE83W2.fastq.gzad94bfa6-99ff-47d3-9a68-2da994cf70cd\n",
      "response from aws was: \n",
      " {u'startDate': datetime.datetime(2018, 3, 25, 8, 11, 51, 290000, tzinfo=tzlocal()), 'ResponseMetadata': {'RetryAttempts': 0, 'HTTPStatusCode': 200, 'RequestId': 'b329bc18-3025-11e8-86dd-e7203302ff1b', 'HTTPHeaders': {'x-amzn-requestid': 'b329bc18-3025-11e8-86dd-e7203302ff1b', 'content-length': '181', 'content-type': 'application/x-amz-json-1.0'}}, u'executionArn': u'arn:aws:states:us-east-1:643366669028:execution:tibanna_pony:fastqc-0-11-4-1_4DNFIGJE83W2.fastq.gzad94bfa6-99ff-47d3-9a68-2da994cf70cd'}\n",
      "url to view status:\n",
      "https://console.aws.amazon.com/states/home?region=us-east-1#/executions/details/arn:aws:states:us-east-1:643366669028:execution:tibanna_pony:fastqc-0-11-4-1_4DNFIGJE83W2.fastq.gzad94bfa6-99ff-47d3-9a68-2da994cf70cd\n",
      "\n",
      "fastqc running for 4DNFICCCJGVK\n",
      "about to start run fastqc-0-11-4-1_4DNFICCCJGVK.fastq.gz47e5e972-aef2-4318-bf37-3df97706b24d\n",
      "response from aws was: \n",
      " {u'startDate': datetime.datetime(2018, 3, 25, 8, 11, 57, 926000, tzinfo=tzlocal()), 'ResponseMetadata': {'RetryAttempts': 0, 'HTTPStatusCode': 200, 'RequestId': 'b71eeab0-3025-11e8-b383-0b445d145b65', 'HTTPHeaders': {'x-amzn-requestid': 'b71eeab0-3025-11e8-b383-0b445d145b65', 'content-length': '182', 'content-type': 'application/x-amz-json-1.0'}}, u'executionArn': u'arn:aws:states:us-east-1:643366669028:execution:tibanna_pony:fastqc-0-11-4-1_4DNFICCCJGVK.fastq.gz47e5e972-aef2-4318-bf37-3df97706b24d'}\n",
      "url to view status:\n",
      "https://console.aws.amazon.com/states/home?region=us-east-1#/executions/details/arn:aws:states:us-east-1:643366669028:execution:tibanna_pony:fastqc-0-11-4-1_4DNFICCCJGVK.fastq.gz47e5e972-aef2-4318-bf37-3df97706b24d\n",
      "\n",
      "101\n",
      "202\n",
      "4DNFIT2OY9HJ does not have the md5sum calculated during upload\n",
      "4DNFIVJZKL9R does not have the md5sum calculated during upload\n",
      "303\n",
      "4DNFISY5ED3Q does not have the md5sum calculated during upload\n",
      "4DNFIDCLJ6LY does not have the md5sum calculated during upload\n",
      "An error occurred (404) when calling the HeadObject operation: Not Found\n",
      "4DNFIH77OSA2 does not have a file in S3\n",
      "404\n",
      "4DNFI82SFXBP does not have the md5sum calculated during upload\n",
      "4DNFIF58NXJY does not have the md5sum calculated during upload\n",
      "505\n",
      "An error occurred (404) when calling the HeadObject operation: Not Found\n",
      "4DNFILF1UY2Y does not have a file in S3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred (404) when calling the HeadObject operation: Not Found\n",
      "4DNFI88R8KZ7 does not have a file in S3\n",
      "An error occurred (404) when calling the HeadObject operation: Not Found\n",
      "4DNFI4IKEMGX does not have a file in S3\n",
      "606\n",
      "An error occurred (404) when calling the HeadObject operation: Not Found\n",
      "4DNFI5LI1ZLM does not have a file in S3\n",
      "An error occurred (404) when calling the HeadObject operation: Not Found\n",
      "4DNFINBXXW77 does not have a file in S3\n",
      "An error occurred (404) when calling the HeadObject operation: Not Found\n",
      "4DNFIY13CD93 does not have a file in S3\n",
      "An error occurred (404) when calling the HeadObject operation: Not Found\n",
      "4DNFI43RP96B does not have a file in S3\n",
      "An error occurred (404) when calling the HeadObject operation: Not Found\n",
      "4DNFI8KTY3QD does not have a file in S3\n",
      "4DNFIPBQPYG5 does not have the md5sum calculated during upload\n",
      "4DNFIZUZHKUP does not have the md5sum calculated during upload\n",
      "707\n",
      "808\n",
      "909\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-47e43a1ac7cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0mfile_resp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accession'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"does not have a file in S3\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0mfile_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msummarize_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_resp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-47e43a1ac7cb>\u001b[0m in \u001b[0;36msummarize_file\u001b[0;34m(file_resp)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mworkflows\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma_wfr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mworkflows\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             \u001b[0mwfr_resp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mff_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_wfr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'uuid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m             \u001b[0mwfr_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwfr_resp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'display_title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwfr_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwf_md5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/koray/Github/tibanna/core/ff_utils.pyc\u001b[0m in \u001b[0;36mget_metadata\u001b[0;34m(obj_id, key, connection, frame)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"object\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;31m# default to always get from database\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m     \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfdn_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m     \u001b[0msleep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mwait\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msleep\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tasks import run_md5\n",
    "from tasks import run_fastqc\n",
    "from invoke import run\n",
    "import time\n",
    "from datetime import datetime\n",
    "from core.utils import Tibanna\n",
    "from core import ff_utils\n",
    "\n",
    "wf_md5 = \"md5\"\n",
    "wf_fastqc = \"fastqc-0-11-4-1\"\n",
    "\n",
    "env = 'fourfront-webprod'\n",
    "tibanna = Tibanna(env=env)\n",
    "run_md_qc = raw_input(\"Do you wanna run md5 and/or fastqc if missing? (md5/qc/all/none)\")\n",
    "\n",
    "# status for completion\n",
    "# there are two flavors of complete signals, before it was output_file_transfer_finished, not it is complete.\n",
    "# old completed wf runs have former one.\n",
    "\n",
    "ff = ff_utils.fdn_connection(key=tibanna.ff_keys)\n",
    "\n",
    "################\n",
    "##ADD TO WORKFLOW\n",
    "# wfr_time = datetime.strptime(wfr_data['date_created'],'%Y-%m-%dT%H:%M:%S.%f+00:00')\n",
    "# run_hours = int((datetime.now()-wfr_time).total_seconds()/3600)\n",
    "################\n",
    "\n",
    "def get_files(exp_set_id):\n",
    "    files = []\n",
    "    exps = ff_utils.get_metadata(exp_set_id, connection=ff)['experiments_in_set']\n",
    "    for an_exp in exps:\n",
    "        exp_resp = ff_utils.get_metadata(an_exp, connection=ff)['files']\n",
    "        files.extend(exp_resp)\n",
    "    return files\n",
    "\n",
    "def summarize_file(file_resp):\n",
    "    md5 = False\n",
    "    qc = False\n",
    "    file_id = file_resp['accession']\n",
    "    sequencer = file_resp.get('instrument')\n",
    "    relations = file_resp.get('related_files')\n",
    "    status = file_resp.get('status')\n",
    "    workflows = file_resp.get('workflow_run_inputs')\n",
    "    first_alias = file_resp.get('aliases',[None])[0]\n",
    "    pair_no = file_resp.get('paired_end')\n",
    "    # is md5 fine\n",
    "    if file_resp.get('content_md5sum'):\n",
    "        md5 = True\n",
    "    # is there md5sum for gzip\n",
    "    if not file_resp.get('md5sum'):\n",
    "        print file_id,\"does not have the md5sum calculated during upload\"\n",
    "        \n",
    "    # is there a qc?\n",
    "    if file_resp.get('quality_metric'):\n",
    "        qc = True\n",
    "    # Check workflows for qc fastqc workflow partA\n",
    "    md5_status = 'did_not_run'\n",
    "    fastqc_status = 'did_not_run'\n",
    "    # Assumes workflow_runs come in time ordered list, and grabs the last ones for each wf run\n",
    "    if workflows:\n",
    "        for a_wfr in workflows:\n",
    "            wfr_resp = ff_utils.get_metadata(a_wfr['uuid'], connection=ff)\n",
    "            wfr_name = wfr_resp['display_title']\n",
    "            if wfr_name.startswith(wf_md5):\n",
    "                md5_status = wfr_resp.get('run_status')     \n",
    "            elif wfr_name.startswith(wf_fastqc):\n",
    "                fastqc_status = wfr_resp.get('run_status') \n",
    "            \n",
    "                \n",
    "    # Check for md5 and fastqc, and if not complete, run or report it. \n",
    "    # if exclude miseq is on, do this only if sequencer is not miseq\n",
    "\n",
    "    if not md5 or status in [\"uploading\", \"upload failed\"] or md5_status != 'complete':\n",
    "        # if not, shall we run it?\n",
    "        if run_md_qc in ['md5', 'all']:\n",
    "            print 'md5 running for', file_resp['accession']\n",
    "            code_md5= \"invoke run_md5 \" + env + \" \" + file_resp['accession'] + \" \" + file_resp['uuid']\n",
    "            run(code_md5)\n",
    "            print ''\n",
    "            time.sleep(3)\n",
    "        # user does not want it to be run, so just report\n",
    "        else:\n",
    "            print 'md5 run missing for', file_resp['accession']\n",
    "    # check fastqc if md5 is fine\n",
    "    else:\n",
    "        if not qc or fastqc_status != 'complete':\n",
    "            # if not, shall we run it?\n",
    "            if run_md_qc in ['qc', 'all']:\n",
    "                print 'fastqc running for', file_resp['accession']\n",
    "                code_qc= \"invoke run_fastqc \" + env + \" \" + file_resp['accession'] + \" \" + file_resp['uuid']\n",
    "                run(code_qc)\n",
    "                print ''    \n",
    "                time.sleep(3)\n",
    "            # user does not want it to be run, so just report\n",
    "            else:\n",
    "                print 'fastqc run missing for', file_resp['accession'], fastqc_status\n",
    "                print \n",
    "    return\n",
    "\n",
    "\n",
    "file_url = '/search/?type=FileFastq&limit=all&q=date_created%3A%3E%3D2016-09-01'\n",
    "all_files = ff_utils.get_metadata('files-fastq', connection=ff)['@graph']\n",
    "\n",
    "print len(all_files)\n",
    "\n",
    "\n",
    "printn = 0\n",
    "counter = 0\n",
    "for a_file in all_files:  \n",
    "    counter += 1\n",
    "    # check for deleted or weird cases\n",
    "    try:\n",
    "        if a_file['status'] == 'deleted':\n",
    "            #print \"Deleted File\", a_file\n",
    "            continue\n",
    "    except:\n",
    "        print a_file\n",
    "        break\n",
    "        \n",
    "    if counter-printn > 100:\n",
    "        print counter\n",
    "        printn = counter\n",
    "\n",
    "    file_resp = ff_utils.get_metadata(a_file['uuid'], connection=ff, frame='embedded')\n",
    "    # check if file is in s3\n",
    "    head_info = tibanna.s3.does_key_exist(file_resp['upload_key'], tibanna.s3.raw_file_bucket)\n",
    "    if not head_info:\n",
    "        print file_resp['accession'], \"does not have a file in S3\"\n",
    "        continue\n",
    "    file_info = summarize_file(file_resp)\n",
    "    \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

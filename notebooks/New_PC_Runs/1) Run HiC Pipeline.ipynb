{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.utils import Tibanna\n",
    "from core import ff_utils\n",
    "from core.utils import run_workflow\n",
    "from datetime import datetime\n",
    "from core.wfr import *\n",
    "\n",
    "env = 'fourfront-webprod'\n",
    "tibanna = Tibanna(env=env)\n",
    "tibanna.ff_keys['default']['server'] = 'https://data.4dnucleome.org'\n",
    "ff = ff_utils.fdn_connection(key=tibanna.ff_keys)\n",
    "tibanna.ff_keys['default']['server'] = 'https://data.4dnucleome.org'\n",
    "exclude_miseq = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89\n",
      "\n",
      "27 4DNES6V4HVDE\n",
      "HindIII human\n",
      "4DNEXNIZPGD6 part1 complete\n",
      "4DNEXNIZPGD6 part2 complete\n",
      "mergedpairs\n",
      "[]\n",
      "0\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# for a given experiment set and some parameters like instrument\n",
    "# print set of files and their partA hic workflow status\n",
    "# if there are one that are running report the number of running cases\n",
    "# if there are file pairs that don't have a corresponding part A, report them separately\n",
    "\n",
    "wf_dict =[\n",
    "    {'wf_name': 'bwa-mem',\n",
    "     'wf_uuid': '3feedadc-50f9-4bb4-919b-09a8b731d0cc',\n",
    "     'parameters':{\"nThreads\": 16},\n",
    "    },\n",
    "    {'wf_name': 'hi-c-processing-bam',\n",
    "     'wf_uuid': '023bfb3e-9a8b-42b9-a9d4-216079526f68',\n",
    "     'parameters':{\"nthreads_merge\": 16, \"nthreads_parse_sort\": 16},\n",
    "    },\n",
    "    {'wf_name': 'hi-c-processing-pairs',\n",
    "     'wf_uuid': 'c9e0e6f7-b0ed-4a42-9466-cadc2dd84df0',\n",
    "     'parameters': {\"nthreads\": 1, \"maxmem\": \"32g\"},\n",
    "    }    \n",
    "]\n",
    "\n",
    "# url for hic exps\n",
    "exp_types = ['in%20situ%20Hi-C', 'dilution%20Hi-C']\n",
    "set_url = '/search/?'+'&'.join(['experiments_in_set.experiment_type='+i for i in exp_types])+'&type=ExperimentSetReplicate'\n",
    "run_sets = ff_utils.get_metadata(set_url , connection=ff)['@graph']\n",
    "\n",
    "add_pc = False\n",
    "add_rel = False\n",
    "add_wfr = False\n",
    "\n",
    "#test_set = '4DNES2R6PUEK'\n",
    "#test_set = '4DNESZ2PVZWR'\n",
    "#run_sets = [ff_utils.get_metadata(test_set , connection=ff)]\n",
    "counter = 0\n",
    "completed = 0\n",
    "completed_acc = []\n",
    "print len(run_sets)\n",
    "for a_set in run_sets: \n",
    "    counter += 1\n",
    "    \n",
    "    \n",
    "    if counter < 27:\n",
    "        continue\n",
    "\n",
    "    print\n",
    "    if \"HiC_Pipeline_0.2.5\" in a_set.get('completed_processes', []):\n",
    "        print counter, a_set['accession'], 'complete'\n",
    "        continue  \n",
    "\n",
    "    fastqpairs, organism, enzyme, bwa_ref, chrsize_ref, enz_ref, f_size = find_pairs(a_set, exclude_miseq, ff, tibanna)\n",
    "    \n",
    "    if organism not in  ['human', 'mouse']:\n",
    "        print counter, a_set['accession'], 'skipping non human and mouse'\n",
    "        continue\n",
    "    \n",
    "    if enzyme not in ['MboI', 'DpnII', 'HindIII']:\n",
    "        print counter, a_set['accession'], 'skipping not ready NZ', enzyme\n",
    "        continue\n",
    "    \n",
    "    if f_size < 10:\n",
    "        print counter, a_set['accession'], 'skipping small file size', str(f_size) \n",
    "        continue\n",
    "        \n",
    "        \n",
    "    print counter, a_set['accession']\n",
    "    print enzyme, organism\n",
    "    part3 = 'done'\n",
    "    list_release = []\n",
    "    set_pairs = []        \n",
    "    # cycle through the experiments\n",
    "    for exp in fastqpairs.keys():\n",
    "        if not fastqpairs.get(exp):\n",
    "            print(exp, 'does not have any fastq pairs')\n",
    "            continue\n",
    "        # Check Part 1 and See if all are okay\n",
    "        exp_bams = []\n",
    "        part1 = 'done'\n",
    "        part2 = 'done'\n",
    "        for pair in fastqpairs[exp]:\n",
    "            #############\n",
    "            bam1 = get_wfr_out(pair[0], 'bwa-mem 0.2.5', 'bam', ff)\n",
    "            bam2 = get_wfr_out(pair[1], 'bwa-mem 0.2.5', 'bam', ff)\n",
    "            # if run is not successful\n",
    "            if bam1.startswith('no') or not bam1 or bam1 != bam2:\n",
    "                part1 = 'not ready'\n",
    "                if add_wfr:\n",
    "                    if not bwa_index:\n",
    "                        print 'not yet usable', organism\n",
    "                        continue\n",
    "                    inp_f = {'fastq1':pair[0], 'fastq2':pair[1], 'bwa_index':bwa_ref}\n",
    "                    name_tag = pair[0].split('/')[2]+'_'+pair[1].split('/')[2]\n",
    "                    run_missing_wfr(wf_dict[0], inp_f, name_tag, ff, env, tibanna)\n",
    "            elif bam1 == 'running':\n",
    "                part1 = 'still running'\n",
    "                print('part1 still running')\n",
    "            # if successful\n",
    "            else:\n",
    "                exp_bams.append(bam1)\n",
    "                list_release.append(bam1)\n",
    "        # stop progress to part2 \n",
    "        if part1 is not 'done':\n",
    "            print exp, 'has missing Part1 runs'\n",
    "            part2 = 'not ready'\n",
    "            part3 = 'not ready'\n",
    "            continue\n",
    "        print exp, 'part1 complete'\n",
    "        #check if part 2 is run already, it not start the run\n",
    "        exp_com_bam = []\n",
    "        exp_pairs = []\n",
    "        for bam in exp_bams:\n",
    "            com_bam = get_wfr_out(bam, 'hi-c-processing-bam 0.2.5', 'bam', ff)\n",
    "            pairs = get_wfr_out(bam, 'hi-c-processing-bam 0.2.5', 'pairs', ff)\n",
    "            # try to run if missing\n",
    "            if pairs.startswith('no') or not pairs:\n",
    "                part2 = 'not ready' \n",
    "            elif pairs == 'running':\n",
    "                part2 = 'still running'\n",
    "                print('part2 still running')\n",
    "            else:\n",
    "                exp_com_bam.append(com_bam)\n",
    "                exp_pairs.append(pairs)\n",
    "        \n",
    "        # make sure all bams went through the same wfr and produces same file\n",
    "        if part2 != 'done' or len(list(set(exp_com_bam))) != 1 or len(list(set(exp_pairs))) !=1:\n",
    "            print exp, 'Part2 did not complete'\n",
    "            part3 = 'not ready' \n",
    "        \n",
    "            if add_wfr:\n",
    "                if not chrsize_ref:\n",
    "                    print 'not yet usable', organism\n",
    "                    continue\n",
    "                # make sure no duplicates\n",
    "                inp_f = {'input_bams':exp_bams, 'chromsize':chrsize_ref}           \n",
    "                run_missing_wfr(wf_dict[1], inp_f, exp, ff, env, tibanna)   \n",
    "            continue\n",
    "            \n",
    "        # add bam and pairs to exp proc file\n",
    "        list_release.extend([exp_com_bam[0],exp_pairs[0]])\n",
    "        if add_pc:\n",
    "            add_processed_files(exp, [exp_com_bam[0],exp_pairs[0]], ff)\n",
    "        \n",
    "        print exp, 'part2 complete'\n",
    "        set_pairs.append(exp_pairs[0])\n",
    "    \n",
    "    if part3 != 'done':\n",
    "        print 'Part3 not ready'\n",
    "        continue\n",
    "    \n",
    "    if not set_pairs:\n",
    "        print 'no pairs can be produced from this set'\n",
    "        continue\n",
    "        \n",
    "    merged_pairs = []\n",
    "    for set_pair in set_pairs:\n",
    "        merged_pair = get_wfr_out(set_pair, 'hi-c-processing-pairs 0.2.5', 'pairs', ff)\n",
    "        hic = get_wfr_out(set_pair, 'hi-c-processing-pairs 0.2.5', 'hic', ff)\n",
    "        mcool = get_wfr_out(set_pair, 'hi-c-processing-pairs 0.2.5', 'mcool', ff)\n",
    "        normvec = get_wfr_out(set_pair, 'hi-c-processing-pairs 0.2.5', 'normvector_juicerformat', ff)\n",
    "        print('mergedpairs')\n",
    "        print(merged_pairs)\n",
    "        if merged_pair.startswith('no') or not merged_pair:\n",
    "            part3 = 'part3 did not complete'\n",
    "            break\n",
    "        elif merged_pair == 'running':\n",
    "            part3 = 'still running'\n",
    "            break\n",
    "        else:\n",
    "            merged_pairs.append(merged_pair)\n",
    "    break     \n",
    "\n",
    "                \n",
    "    if part3 != 'done' or len(list(set(merged_pairs))) != 1:\n",
    "        print a_set['accession'], 'is missing Part3'\n",
    "        part3 = 'not ready'\n",
    "        \n",
    "        # if part3 is still running report it, and skip the rest of the script\n",
    "        if part3 == 'still running':\n",
    "            print 'part3', part3\n",
    "            \n",
    "        # if it is not run, and add_wfr is true, go for it, then skip the rest of the script\n",
    "        elif add_wfr:\n",
    "            if not chrsize_ref:\n",
    "                print 'not yet usable', organism\n",
    "                continue\n",
    "\n",
    "            if not enz_ref:\n",
    "                print 'restriction enzyme not ready for', organism, enzyme\n",
    "                continue\n",
    "            inp_f = {'input_pairs':set_pairs, 'chromsizes':chrsize_ref, 'restriction_file': enz_ref} \n",
    "            #run_missing_wfr(wf_dict[2], inp_f, a_set['accession'], ff, env, tibanna)\n",
    "        \n",
    "        continue\n",
    "    #####\n",
    "    #add competed flag to experiment\n",
    "    if add_pc and add_rel:\n",
    "        ff_utils.patch_metadata({\"completed_processes\":[\"HiC_Pipeline_0.2.5\"]}, obj_id=a_set['accession'] ,connection=ff)\n",
    "    \n",
    "    # add processed files to set\n",
    "    list_release.extend([merged_pair, hic, mcool, normvec])\n",
    "    if add_pc:\n",
    "        add_processed_files(a_set['accession'], [merged_pair, hic, mcool, normvec], ff)\n",
    "    \n",
    "    #release files and wfrs\n",
    "    if add_rel:\n",
    "        release_files(a_set['accession'], list(set(list_release)), ff)\n",
    "    \n",
    "    completed += 1\n",
    "    completed_acc.append(a_set['accession'])\n",
    "    print a_set['accession'], 'part3 complete'\n",
    "\n",
    "    \n",
    "print completed\n",
    "print completed_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from core.utils import Tibanna\n",
    "from core import ff_utils\n",
    "from core.utils import run_workflow\n",
    "\n",
    "env = 'fourfront-webprod'\n",
    "tibanna = Tibanna(env=env)\n",
    "ff = ff_utils.fdn_connection(key=tibanna.ff_keys)\n",
    "raw_bucket = tibanna.s3.raw_file_bucket\n",
    "out_bucket = tibanna.s3.outfile_bucket\n",
    "exclude_miseq = True\n",
    "\n",
    "\n",
    "def find_pairs(my_rep_set):\n",
    "    \"\"\"Find pairs and make sure they are fine my qc.\n",
    "    \"\"\"\n",
    "    report = {}\n",
    "    rep_resp = my_rep_set['experiments_in_set']\n",
    "    enzymes = []\n",
    "    organisms = []\n",
    "    for exp in rep_resp:\n",
    "        exp_resp = ff_utils.get_metadata(exp, connection=ff)\n",
    "        report[exp_resp['accession']] = []\n",
    "        if not organisms:\n",
    "            biosample = ff_utils.get_metadata(exp_resp['biosample'], connection=ff, frame='embedded')      \n",
    "            organisms = list(set([bs['individual']['organism']['display_title'] for bs in biosample['biosource']]))\n",
    "            if len(organisms) != 1:\n",
    "                print 'multiple organisms in set', my_rep_set['accession']\n",
    "                break\n",
    "        exp_files = exp_resp['files']\n",
    "        enzyme = exp_resp.get('digestion_enzyme')\n",
    "        enzymes.append(enzyme)\n",
    "        for fastq_file in exp_files:\n",
    "            file_resp = ff_utils.get_metadata(fastq_file, connection=ff)  \n",
    "            # skip pair no 2\n",
    "            if file_resp.get('paired_end')=='2':\n",
    "                continue \n",
    "            # exclude miseq\n",
    "            if exclude_miseq:\n",
    "                if file_resp.get('instrument') == 'Illumina MiSeq':\n",
    "                    print 'skipping miseq files', exp\n",
    "                    continue\n",
    "                \n",
    "            #Some checks before running\n",
    "            #check if status is deleted\n",
    "            if file_resp['status'] == 'deleted':\n",
    "                print 'deleted file', file_resp['accession'], 'in', my_rep_set['accession']\n",
    "                continue\n",
    "            #if no uploaded file in the file item report and skip\n",
    "            if not file_resp.get('filename'):\n",
    "                print file_resp['accession'], \"does not have a file\"\n",
    "                continue\n",
    "            # check if file is in s3\n",
    "            head_info = tibanna.s3.does_key_exist(file_resp['upload_key'], tibanna.s3.raw_file_bucket)\n",
    "            if not head_info:\n",
    "                print file_resp['accession'], \"does not have a file in S3\"\n",
    "                continue\n",
    "            # check that file has a pair\n",
    "            f1 = file_resp['@id']\n",
    "            f2 = ''\n",
    "            relations = file_resp.get('related_files')\n",
    "            for relation in relations:\n",
    "                if relation['relationship_type'] == 'paired with':\n",
    "                    f2 = relation['file']\n",
    "            if not f2:\n",
    "                print f1, 'does not have a pair'\n",
    "                continue\n",
    "            report[exp_resp['accession']].append((f1, f2))\n",
    "            \n",
    "    # get the organism\n",
    "    if len(list(set(organisms))) == 1:\n",
    "        organism = organisms[0]\n",
    "    else:\n",
    "        organism = None\n",
    "        print 'problematic organism', set(organisms)\n",
    "        \n",
    "    # get the enzyme\n",
    "    if len(list(set(enzymes))) == 1:\n",
    "        enz = enzymes[0].split('/')[2]\n",
    "    else:\n",
    "        enz = None\n",
    "        print 'problematic enzyme', set(enzymes)\n",
    "    return report, organism, enz\n",
    "\n",
    "\n",
    "def get_wfr_out(file_id, wfr_name, file_format):\n",
    "    emb_file = ff_utils.get_metadata(file_id, connection=ff, frame = 'embedded')\n",
    "    workflows = emb_file.get('workflow_run_inputs')\n",
    "    wfr = {}\n",
    "    run_status = 'did not run'\n",
    "    if workflows:\n",
    "        for a_wfr in workflows:\n",
    "            wfr_resp = ff_utils.get_metadata(a_wfr['uuid'], connection=ff)  \n",
    "            wfr_resp_name = wfr_resp['display_title']\n",
    "            if wfr_resp_name.startswith(wfr_name):\n",
    "                wfr = wfr_resp\n",
    "                run_status = wfr_resp['run_status']\n",
    "    else:\n",
    "        return \"no workflow in file\"\n",
    "    \n",
    "    if run_status == 'complete':\n",
    "        outputs = wfr.get('output_files')\n",
    "        file_id = [i['value'] for i in outputs if i['format'] == file_format][0]\n",
    "        if file_id:\n",
    "            return file_id\n",
    "        else:\n",
    "            return \"no file found\"\n",
    "    else:\n",
    "        return \"no completed run\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89\n",
      "9 4DNESRJ8KV4Q complete\n",
      "/files-processed/4DNFI7JNCNFB/\n",
      "fine\n",
      "11 4DNES78Y8Y5K complete\n",
      "/files-processed/4DNFISWCOKN2/\n",
      "fine\n",
      "12 4DNESB6MNCFE complete\n",
      "/files-processed/4DNFIQJQY7PW/\n",
      "fine\n",
      "14 4DNES8J78WV2 complete\n",
      "/files-processed/4DNFIPNC6K5B/\n",
      "fine\n",
      "15 4DNESAPF27TG complete\n",
      "/files-processed/4DNFIK6HMOII/\n",
      "fine\n",
      "23 4DNES9L4AK6Q complete\n",
      "/files-processed/4DNFIMDOXUT8/\n",
      "fine\n",
      "24 4DNES2M5JIGV complete\n",
      "/files-processed/4DNFI6HDY7WZ/\n",
      "fine\n",
      "26 4DNESLLTENG9 complete\n",
      "/files-processed/4DNFI3UNF9VB/\n",
      "fine\n",
      "28 4DNES98CI6GV complete\n",
      "/files-processed/4DNFIJYULXT7/\n",
      "fine\n",
      "29 4DNESC5J3EIX complete\n",
      "/files-processed/4DNFI2T49EAG/\n",
      "fine\n",
      "30 4DNES21NPLZU complete\n",
      "/files-processed/4DNFIH77QBT5/\n",
      "fine\n",
      "31 4DNESYTIFTEE complete\n",
      "/files-processed/4DNFIQI8SFNE/\n",
      "fine\n",
      "32 4DNESIG4ELE4 complete\n",
      "/files-processed/4DNFIIH3SM5N/\n",
      "fine\n",
      "34 4DNESNHN919R complete\n",
      "/files-processed/4DNFILC1IPOE/\n",
      "fine\n",
      "35 4DNES8ZUV5CQ complete\n",
      "/files-processed/4DNFI5K8L94P/\n",
      "fine\n",
      "36 4DNESCCP4KTY complete\n",
      "/files-processed/4DNFIFD991IA/\n",
      "fine\n",
      "37 4DNEST9AVULS complete\n",
      "/files-processed/4DNFICYNMTJG/\n",
      "fine\n",
      "38 4DNES7DFQZLI complete\n",
      "/files-processed/4DNFIGBYT93X/\n",
      "fine\n",
      "39 4DNESFBT9P4O complete\n",
      "/files-processed/4DNFIW1QGEFN/\n",
      "fine\n",
      "40 4DNESE3ICNE1 complete\n",
      "/files-processed/4DNFIEWJXIW4/\n",
      "fine\n",
      "42 4DNES4GSP9S4 complete\n",
      "/files-processed/4DNFIM8SM3SD/\n",
      "fine\n",
      "43 4DNESTAPSPUC complete\n",
      "/files-processed/4DNFIHGNUBH5/\n",
      "fine\n",
      "44 4DNESI2UKI7P complete\n",
      "/files-processed/4DNFIFXDDDJ6/\n",
      "fine\n",
      "45 4DNESJ1VX52C complete\n",
      "/files-processed/4DNFIUZJP1ED/\n",
      "fine\n",
      "46 4DNESHGL976U complete\n",
      "/files-processed/4DNFIM8KVPS6/\n",
      "fine\n",
      "48 4DNESYUYFD6H complete\n",
      "/files-processed/4DNFIIRNP38T/\n",
      "fine\n",
      "55 4DNESUTEOMGQ complete\n",
      "/files-processed/4DNFINSKEZND/\n",
      "fine\n",
      "68 4DNESOSE2FYZ complete\n",
      "/files-processed/4DNFINKFRVWU/\n",
      "fine\n",
      "69 4DNESEW5JLUC complete\n",
      "/files-processed/4DNFIGWTMK9Y/\n",
      "fine\n",
      "70 4DNESHFBC56P complete\n",
      "/files-processed/4DNFIRMZ7QTE/\n",
      "fine\n",
      "71 4DNESDEK4IH8 complete\n",
      "/files-processed/4DNFI5IHU27G/\n",
      "fine\n",
      "72 4DNESI7DEJTM complete\n",
      "/files-processed/4DNFI18UHVRO/\n",
      "fine\n",
      "75 4DNESUB35TII complete\n",
      "/files-processed/4DNFIWCH6ADP/\n",
      "fine\n",
      "76 4DNESIE5R9HS complete\n",
      "/files-processed/4DNFIGUIV5KO/\n",
      "fine\n",
      "77 4DNESSM1H92K complete\n",
      "/files-processed/4DNFIABB3FHQ/\n",
      "fine\n",
      "78 4DNES1ZEJNRU complete\n",
      "/files-processed/4DNFIJTOIGOI/\n",
      "fine\n",
      "79 4DNES4269GKX complete\n",
      "/files-processed/4DNFI2ZUCIHD/\n",
      "fine\n",
      "84 4DNESPXW8XHY complete\n",
      "/files-processed/4DNFIW9WZRGA/\n",
      "fine\n",
      "85 4DNESLLA3R1V complete\n",
      "/files-processed/4DNFI3PNAYBK/\n",
      "fine\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# for a given experiment set and some parameters like instrument\n",
    "# print set of files and their partA hic workflow status\n",
    "# if there are one that are running report the number of running cases\n",
    "# if there are file pairs that don't have a corresponding part A, report them separately\n",
    "\n",
    "wf_dict =[\n",
    "    {'wf_name': 'bwa-mem',\n",
    "     'wf_uuid': '3feedadc-50f9-4bb4-919b-09a8b731d0cc',\n",
    "     'parameters':{\"nThreads\": 16},\n",
    "    },\n",
    "    {'wf_name': 'hi-c-processing-bam',\n",
    "     'wf_uuid': '023bfb3e-9a8b-42b9-a9d4-216079526f68',\n",
    "     'parameters':{\"nthreads_merge\": 16, \"nthreads_parse_sort\": 16},\n",
    "    },\n",
    "    {'wf_name': 'hi-c-processing-pairs',\n",
    "     'wf_uuid': 'c9e0e6f7-b0ed-4a42-9466-cadc2dd84df0',\n",
    "     'parameters': {\"nthreads\": 1, \"maxmem\": \"32g\"},\n",
    "    }    \n",
    "]\n",
    "\n",
    "# url for hic exps\n",
    "exp_types = ['in%20situ%20Hi-C', 'dilution%20Hi-C']\n",
    "set_url = '/search/?'+'&'.join(['experiments_in_set.experiment_type='+i for i in exp_types])+'&type=ExperimentSetReplicate'\n",
    "run_sets = ff_utils.get_metadata(set_url , connection=ff)['@graph']\n",
    "\n",
    "add_pc = False\n",
    "add_rel = False\n",
    "add_wfr = False\n",
    "\n",
    "#test_set = '4DNES2R6PUEK'\n",
    "#test_set = '4DNESZ2PVZWR'\n",
    "#run_sets = [ff_utils.get_metadata(test_set , connection=ff)]\n",
    "counter = 0\n",
    "completed = 0\n",
    "completed_acc = []\n",
    "print len(run_sets)\n",
    "for a_set in run_sets: \n",
    "    counter += 1\n",
    "     \n",
    "    if a_set.get('completed_processes') == [\"HiC_Pipeline_0.2.5\"]:\n",
    "        print counter, a_set['accession'], 'complete'    \n",
    "    else:\n",
    "        continue\n",
    "    fastqpairs, organism, enzyme = find_pairs(a_set)    \n",
    "    for exp in fastqpairs.keys():\n",
    "        if not fastqpairs.get(exp):\n",
    "            print(exp, 'does not have any fastq pairs')\n",
    "            continue\n",
    "        # Check Part 1 and See if all are okay\n",
    "        for pair in fastqpairs[exp]:\n",
    "            #p1\n",
    "            bam1 = get_wfr_out(pair[0], 'bwa-mem 0.2.5', 'bam')\n",
    "            #p2\n",
    "            com_bam = get_wfr_out(bam1, 'hi-c-processing-bam 0.2.5', 'bam')\n",
    "            pairs = get_wfr_out(bam1, 'hi-c-processing-bam 0.2.5', 'pairs')\n",
    "            #p3\n",
    "            mcool = get_wfr_out(pairs, 'hi-c-processing-pairs 0.2.5', 'mcool')\n",
    "            # merged_pair = get_wfr_out(pairs, 'hi-c-processing-pairs 0.2.5', 'pairs')\n",
    "            # hic = get_wfr_out(pairs, 'hi-c-processing-pairs 0.2.5', 'hic')\n",
    "            # normvec = get_wfr_out(pairs, 'hi-c-processing-pairs 0.2.5', 'normvector_juicerformat')\n",
    "            print(mcool)\n",
    "            file_resp = ff_utils.get_metadata(mcool, connection=ff)\n",
    "            head_info = tibanna.s3.does_key_exist(file_resp['upload_key'], out_bucket)\n",
    "            if not head_info:\n",
    "                print file_resp['accession'], \"does not have a file in S3\"\n",
    "            else:\n",
    "                print 'fine'\n",
    "            break\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you wanna run md5 and/or fastqc if missing? (md5/qc/all/none)all\n",
      "2993\n",
      "fastqc running for 4DNFIAQ6IFW8\n",
      "about to start run fastqc-0-11-4-1_4DNFIAQ6IFW8.fastq.gz3e043ef4-9e0a-48ed-a08c-c0a1f89fbe4b\n",
      "response from aws was: \n",
      " {u'startDate': datetime.datetime(2018, 5, 1, 15, 29, 38, 981000, tzinfo=tzlocal()), 'ResponseMetadata': {'RetryAttempts': 0, 'HTTPStatusCode': 200, 'RequestId': 'fd37b909-4d75-11e8-af5d-65911bc23b51', 'HTTPHeaders': {'x-amzn-requestid': 'fd37b909-4d75-11e8-af5d-65911bc23b51', 'content-length': '182', 'content-type': 'application/x-amz-json-1.0'}}, u'executionArn': u'arn:aws:states:us-east-1:643366669028:execution:tibanna_pony:fastqc-0-11-4-1_4DNFIAQ6IFW8.fastq.gz3e043ef4-9e0a-48ed-a08c-c0a1f89fbe4b'}\n",
      "url to view status:\n",
      "https://console.aws.amazon.com/states/home?region=us-east-1#/executions/details/arn:aws:states:us-east-1:643366669028:execution:tibanna_pony:fastqc-0-11-4-1_4DNFIAQ6IFW8.fastq.gz3e043ef4-9e0a-48ed-a08c-c0a1f89fbe4b\n",
      "\n",
      "fastqc running for 4DNFI593LRF2\n",
      "about to start run fastqc-0-11-4-1_4DNFI593LRF2.fastq.gz6fa05bfc-dac3-42ec-a3d8-b894bf02c216\n",
      "response from aws was: \n",
      " {u'startDate': datetime.datetime(2018, 5, 1, 15, 29, 46, 815000, tzinfo=tzlocal()), 'ResponseMetadata': {'RetryAttempts': 0, 'HTTPStatusCode': 200, 'RequestId': '01e2562c-4d76-11e8-9fa9-dfbf1fdb54f6', 'HTTPHeaders': {'x-amzn-requestid': '01e2562c-4d76-11e8-9fa9-dfbf1fdb54f6', 'content-length': '182', 'content-type': 'application/x-amz-json-1.0'}}, u'executionArn': u'arn:aws:states:us-east-1:643366669028:execution:tibanna_pony:fastqc-0-11-4-1_4DNFI593LRF2.fastq.gz6fa05bfc-dac3-42ec-a3d8-b894bf02c216'}\n",
      "url to view status:\n",
      "https://console.aws.amazon.com/states/home?region=us-east-1#/executions/details/arn:aws:states:us-east-1:643366669028:execution:tibanna_pony:fastqc-0-11-4-1_4DNFI593LRF2.fastq.gz6fa05bfc-dac3-42ec-a3d8-b894bf02c216\n",
      "\n",
      "101\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-b284b2d6c53c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mprintn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcounter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0mfile_resp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mff_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_file\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'uuid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'embedded'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m     \u001b[0;31m# check if file is in s3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0mhead_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtibanna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoes_key_exist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_resp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'upload_key'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtibanna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_file_bucket\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/koray/Github/tibanna/core/ff_utils.py\u001b[0m in \u001b[0;36mget_metadata\u001b[0;34m(obj_id, key, connection, frame)\u001b[0m\n\u001b[1;32m    284\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfdnDCIC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_FDN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'@type'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tasks import run_md5\n",
    "from tasks import run_fastqc\n",
    "from invoke import run\n",
    "import time\n",
    "from datetime import datetime\n",
    "from core.utils import Tibanna\n",
    "from core import ff_utils\n",
    "\n",
    "wf_md5 = \"md5\"\n",
    "wf_fastqc = \"fastqc-0-11-4-1\"\n",
    "\n",
    "env = 'fourfront-webprod'\n",
    "\n",
    "tibanna = Tibanna(env=env)\n",
    "tibanna.ff_keys['default']['server'] = 'https://data.4dnucleome.org'\n",
    "ff = ff_utils.fdn_connection(key=tibanna.ff_keys)\n",
    "\n",
    "run_md_qc = raw_input(\"Do you wanna run md5 and/or fastqc if missing? (md5/qc/all/none)\")\n",
    "\n",
    "# status for completion\n",
    "# there are two flavors of complete signals, before it was output_file_transfer_finished, not it is complete.\n",
    "# old completed wf runs have former one.\n",
    "\n",
    "\n",
    "\n",
    "################\n",
    "##ADD TO WORKFLOW\n",
    "# wfr_time = datetime.strptime(wfr_data['date_created'],'%Y-%m-%dT%H:%M:%S.%f+00:00')\n",
    "# run_hours = int((datetime.now()-wfr_time).total_seconds()/3600)\n",
    "################\n",
    "\n",
    "def get_files(exp_set_id):\n",
    "    files = []\n",
    "    exps = ff_utils.get_metadata(exp_set_id, connection=ff)['experiments_in_set']\n",
    "    for an_exp in exps:\n",
    "        exp_resp = ff_utils.get_metadata(an_exp, connection=ff)['files']\n",
    "        files.extend(exp_resp)\n",
    "    return files\n",
    "\n",
    "def summarize_file(file_resp):\n",
    "    md5 = False\n",
    "    qc = False\n",
    "    file_id = file_resp['accession']\n",
    "    sequencer = file_resp.get('instrument')\n",
    "    relations = file_resp.get('related_files')\n",
    "    status = file_resp.get('status')\n",
    "    workflows = file_resp.get('workflow_run_inputs')\n",
    "    #first_alias = file_resp.get('aliases',[None])[0]\n",
    "    pair_no = file_resp.get('paired_end')\n",
    "    # is md5 fine\n",
    "    if file_resp.get('content_md5sum'):\n",
    "        md5 = True\n",
    "    # is there md5sum for gzip\n",
    "    if not file_resp.get('md5sum'):\n",
    "        print file_id,\"does not have the md5sum calculated during upload\"\n",
    "        \n",
    "    # is there a qc?\n",
    "    if file_resp.get('quality_metric'):\n",
    "        qc = True\n",
    "    # Check workflows for qc fastqc workflow partA\n",
    "    md5_status = 'did_not_run'\n",
    "    fastqc_status = 'did_not_run'\n",
    "    # Assumes workflow_runs come in time ordered list, and grabs the last ones for each wf run\n",
    "    if workflows:\n",
    "        for a_wfr in workflows:\n",
    "            wfr_resp = ff_utils.get_metadata(a_wfr['uuid'], connection=ff)\n",
    "            wfr_name = wfr_resp['display_title']\n",
    "            if wfr_name.startswith(wf_md5):\n",
    "                md5_status = wfr_resp.get('run_status')     \n",
    "            elif wfr_name.startswith(wf_fastqc):\n",
    "                fastqc_status = wfr_resp.get('run_status') \n",
    "            \n",
    "                \n",
    "    # Check for md5 and fastqc, and if not complete, run or report it. \n",
    "    # if exclude miseq is on, do this only if sequencer is not miseq\n",
    "\n",
    "    if not md5 or status in [\"uploading\", \"upload failed\"] or md5_status != 'complete':\n",
    "        # if not, shall we run it?\n",
    "        if run_md_qc in ['md5', 'all']:\n",
    "            print 'md5 running for', file_resp['accession']\n",
    "            code_md5= \"invoke run_md5 \" + env + \" \" + file_resp['display_title'] + \" \" + file_resp['uuid']\n",
    "            run(code_md5)\n",
    "            print ''\n",
    "            time.sleep(3)\n",
    "        # user does not want it to be run, so just report\n",
    "        else:\n",
    "            print 'md5 run missing for', file_resp['accession']\n",
    "    # check fastqc if md5 is fine\n",
    "    else:\n",
    "        if not qc or fastqc_status != 'complete':\n",
    "            # if not, shall we run it?\n",
    "            if run_md_qc in ['qc', 'all']:\n",
    "                print 'fastqc running for', file_resp['accession']\n",
    "                code_qc= \"invoke run_fastqc \" + env + \" \" + file_resp['display_title'] + \" \" + file_resp['uuid']\n",
    "                run(code_qc)\n",
    "                print ''    \n",
    "                time.sleep(3)\n",
    "            # user does not want it to be run, so just report\n",
    "            else:\n",
    "                print 'fastqc run missing for', file_resp['accession'], fastqc_status\n",
    "                print \n",
    "    return\n",
    "\n",
    "\n",
    "file_url = '/search/?type=FileFastq&limit=all&q=date_created%3A%3E%3D2016-09-01'\n",
    "all_files = ff_utils.get_metadata('files-fastq', connection=ff)['@graph']\n",
    "\n",
    "\n",
    "\n",
    "print len(all_files)\n",
    "\n",
    "\n",
    "printn = 0\n",
    "counter = 0\n",
    "for a_file in all_files:  \n",
    "    counter += 1\n",
    "    # check for deleted or weird cases\n",
    "    try:\n",
    "        if a_file['status'] == 'deleted':\n",
    "            #print \"Deleted File\", a_file\n",
    "            continue\n",
    "    except:\n",
    "        print a_file\n",
    "        break\n",
    "        \n",
    "    if counter-printn > 100:\n",
    "        print counter\n",
    "        printn = counter\n",
    "\n",
    "    file_resp = ff_utils.get_metadata(a_file['uuid'], connection=ff, frame='embedded')\n",
    "    # check if file is in s3\n",
    "    head_info = tibanna.s3.does_key_exist(file_resp['upload_key'], tibanna.s3.raw_file_bucket)\n",
    "    if not head_info:\n",
    "        print file_resp['accession'], \"does not have a file in S3\"\n",
    "        continue\n",
    "    file_info = summarize_file(file_resp)\n",
    "    \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
